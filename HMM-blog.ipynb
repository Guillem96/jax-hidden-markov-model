{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "HMM-blog.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJbbPnKtklfF",
        "colab_type": "text"
      },
      "source": [
        "# Happy Markov Models (HMM)\n",
        "\n",
        "In this article, we are going to generate new words that statistically sound positive. To do so, we are going to use a set of words gathered from a large number of positive reviews found on the internet [1, 2] and using a Hidden Markov Model (HMM).\n",
        "\n",
        "With HMM we will be able to create a language model which will define how positive words are composed, at least how they are statistically composed.\n",
        "\n",
        "To get things even simpler, we are going to use an existing Python package to work with HMMs developed by my own [3].\n",
        "\n",
        "## What are Markov Chains and HMMs?\n",
        "\n",
        "Markov Chains models the way of moving from a determined state $a$ to another state $b$. Each transition has a probability $p_{ab}$ associated meaning how likely is moving from $a$ to $b$. A Markov chain makes a very strong assumption that if we want to predict the future in the sequence, all that matters is the current state (See Equation 1)[4]. \n",
        "\n",
        "$P(q_i=a|q_{i-1}) $\n",
        "\n",
        "*Equation 1: Markov assumption*\n",
        "\n",
        "Figure 1 shows an example of how a Markov Chain looks like.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Guillem96/jax-hidden-markov-model/master/img/mdp.jpg\" width=400/>\n",
        "\n",
        "*Figure 1. Markov chain (Slide comming from Berkeley Reinforcement Learning course)*\n",
        "\n",
        "The HMM is based on augmenting the Markov chain framework. A Markov chain is useful when we need to compute a probability for a sequence of observable events, but sometimes we cannot see what is happening under the hoods. Imagine, that every day, we see a different animal, for instance, the first day we see an ant, the second day a snail, and finally a white fox (Figure 2). What is happening here? Does seeing an ant modifies the probability a snail the following day? It doesn't, what is modifying the probabilities is the weather. Depending on if it is sunny, rainy or snowy we the probabilities of seeing a specific animal varies.\n",
        "\n",
        "![HMM Animals example](https://raw.githubusercontent.com/Guillem96/jax-hidden-markov-model/master/img/HMM%20Example.png)\n",
        "\n",
        "*Figure 2. HMM animals example*\n",
        "\n",
        "An HMM allows us to talk about both observed events(like the animals) and hidden events (like like the weather) that we think of as causal factors in our probabilistic model.  An HMM is specified bythe following components:\n",
        "\n",
        "- $Q = q_1, q_2, q_3, ...$: The set of possible hidden states (Sunny, rainy and snowy)\n",
        "- $O = o_1, o_2, o_3, ...$: A sequence of **observations** sampled from a vocabulary $V$(White Fox, Snail and Ant)\n",
        "- $\\pi = \\pi_1, \\pi_2, \\pi_3,...$: The probability distribution of starting at a determined hidden state.\n",
        "- $A = a_{ij}$: **Transition probabilities**. Matrix that at position $ij$ we find the probability of going from $q_i$ to $q_j$\n",
        "- $ B = b_i(o_t) $: **Emission probabilities**. Probability of observing $o$ being at state $i$ at timestep $t$\n",
        "\n",
        "As Linus would say: *Talk is cheap, show me code*. And this is exactly what I am going to show you. We are going to learn how to formalize the animals example with my own HMM Python package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wEhW-1Qk3LJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "cc992036-9c62-4b50-cdd9-6a64eb1c1599"
      },
      "source": [
        "!git clone https://github.com/Guillem96/jax-hidden-markov-model\n",
        "\n",
        "import sys\n",
        "sys.path.append('jax-hidden-markov-model')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'jax-hidden-markov-model'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/102)\u001b[K\rremote: Counting objects:   1% (2/102)\u001b[K\rremote: Counting objects:   2% (3/102)\u001b[K\rremote: Counting objects:   3% (4/102)\u001b[K\rremote: Counting objects:   4% (5/102)\u001b[K\rremote: Counting objects:   5% (6/102)\u001b[K\rremote: Counting objects:   6% (7/102)\u001b[K\rremote: Counting objects:   7% (8/102)\u001b[K\rremote: Counting objects:   8% (9/102)\u001b[K\rremote: Counting objects:   9% (10/102)\u001b[K\rremote: Counting objects:  10% (11/102)\u001b[K\rremote: Counting objects:  11% (12/102)\u001b[K\rremote: Counting objects:  12% (13/102)\u001b[K\rremote: Counting objects:  13% (14/102)\u001b[K\rremote: Counting objects:  14% (15/102)\u001b[K\rremote: Counting objects:  15% (16/102)\u001b[K\rremote: Counting objects:  16% (17/102)\u001b[K\rremote: Counting objects:  17% (18/102)\u001b[K\rremote: Counting objects:  18% (19/102)\u001b[K\rremote: Counting objects:  19% (20/102)\u001b[K\rremote: Counting objects:  20% (21/102)\u001b[K\rremote: Counting objects:  21% (22/102)\u001b[K\rremote: Counting objects:  22% (23/102)\u001b[K\rremote: Counting objects:  23% (24/102)\u001b[K\rremote: Counting objects:  24% (25/102)\u001b[K\rremote: Counting objects:  25% (26/102)\u001b[K\rremote: Counting objects:  26% (27/102)\u001b[K\rremote: Counting objects:  27% (28/102)\u001b[K\rremote: Counting objects:  28% (29/102)\u001b[K\rremote: Counting objects:  29% (30/102)\u001b[K\rremote: Counting objects:  30% (31/102)\u001b[K\rremote: Counting objects:  31% (32/102)\u001b[K\rremote: Counting objects:  32% (33/102)\u001b[K\rremote: Counting objects:  33% (34/102)\u001b[K\rremote: Counting objects:  34% (35/102)\u001b[K\rremote: Counting objects:  35% (36/102)\u001b[K\rremote: Counting objects:  36% (37/102)\u001b[K\rremote: Counting objects:  37% (38/102)\u001b[K\rremote: Counting objects:  38% (39/102)\u001b[K\rremote: Counting objects:  39% (40/102)\u001b[K\rremote: Counting objects:  40% (41/102)\u001b[K\rremote: Counting objects:  41% (42/102)\u001b[K\rremote: Counting objects:  42% (43/102)\u001b[K\rremote: Counting objects:  43% (44/102)\u001b[K\rremote: Counting objects:  44% (45/102)\u001b[K\rremote: Counting objects:  45% (46/102)\u001b[K\rremote: Counting objects:  46% (47/102)\u001b[K\rremote: Counting objects:  47% (48/102)\u001b[K\rremote: Counting objects:  48% (49/102)\u001b[K\rremote: Counting objects:  49% (50/102)\u001b[K\rremote: Counting objects:  50% (51/102)\u001b[K\rremote: Counting objects:  51% (53/102)\u001b[K\rremote: Counting objects:  52% (54/102)\u001b[K\rremote: Counting objects:  53% (55/102)\u001b[K\rremote: Counting objects:  54% (56/102)\u001b[K\rremote: Counting objects:  55% (57/102)\u001b[K\rremote: Counting objects:  56% (58/102)\u001b[K\rremote: Counting objects:  57% (59/102)\u001b[K\rremote: Counting objects:  58% (60/102)\u001b[K\rremote: Counting objects:  59% (61/102)\u001b[K\rremote: Counting objects:  60% (62/102)\u001b[K\rremote: Counting objects:  61% (63/102)\u001b[K\rremote: Counting objects:  62% (64/102)\u001b[K\rremote: Counting objects:  63% (65/102)\u001b[K\rremote: Counting objects:  64% (66/102)\u001b[K\rremote: Counting objects:  65% (67/102)\u001b[K\rremote: Counting objects:  66% (68/102)\u001b[K\rremote: Counting objects:  67% (69/102)\u001b[K\rremote: Counting objects:  68% (70/102)\u001b[K\rremote: Counting objects:  69% (71/102)\u001b[K\rremote: Counting objects:  70% (72/102)\u001b[K\rremote: Counting objects:  71% (73/102)\u001b[K\rremote: Counting objects:  72% (74/102)\u001b[K\rremote: Counting objects:  73% (75/102)\u001b[K\rremote: Counting objects:  74% (76/102)\u001b[K\rremote: Counting objects:  75% (77/102)\u001b[K\rremote: Counting objects:  76% (78/102)\u001b[K\rremote: Counting objects:  77% (79/102)\u001b[K\rremote: Counting objects:  78% (80/102)\u001b[K\rremote: Counting objects:  79% (81/102)\u001b[K\rremote: Counting objects:  80% (82/102)\u001b[K\rremote: Counting objects:  81% (83/102)\u001b[K\rremote: Counting objects:  82% (84/102)\u001b[K\rremote: Counting objects:  83% (85/102)\u001b[K\rremote: Counting objects:  84% (86/102)\u001b[K\rremote: Counting objects:  85% (87/102)\u001b[K\rremote: Counting objects:  86% (88/102)\u001b[K\rremote: Counting objects:  87% (89/102)\u001b[K\rremote: Counting objects:  88% (90/102)\u001b[K\rremote: Counting objects:  89% (91/102)\u001b[K\rremote: Counting objects:  90% (92/102)\u001b[K\rremote: Counting objects:  91% (93/102)\u001b[K\rremote: Counting objects:  92% (94/102)\u001b[K\rremote: Counting objects:  93% (95/102)\u001b[K\rremote: Counting objects:  94% (96/102)\u001b[K\rremote: Counting objects:  95% (97/102)\u001b[K\rremote: Counting objects:  96% (98/102)\u001b[K\rremote: Counting objects:  97% (99/102)\u001b[K\rremote: Counting objects:  98% (100/102)\u001b[K\rremote: Counting objects:  99% (101/102)\u001b[K\rremote: Counting objects: 100% (102/102)\u001b[K\rremote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 102 (delta 45), reused 72 (delta 27), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (102/102), 353.17 KiB | 1.34 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azy6D2KKnoo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a8257d9-0b7c-4672-8abc-ae0e083d22b4"
      },
      "source": [
        "import jax\n",
        "print('JAX is running on:', jax.lib.xla_bridge.get_backend().platform)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "JAX is running on: gpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flg55q1KklfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import hmm\n",
        "import jax.numpy as np\n",
        "\n",
        "# Decalre the name of the possible Hidden States Q\n",
        "Q_names = ['Sunny', 'Rainy', 'Snowy']\n",
        "\n",
        "# Define the vocabulary of Observations\n",
        "V = ['Ant', 'Snail', 'White Fox']\n",
        "\n",
        "# Define transition probs\n",
        "A = np.array([[0.6, 0.3, 0.1],\n",
        "              [0.4, 0.4, 0.2],\n",
        "              [0.1, 0.4, 0.5]])\n",
        "\n",
        "B = np.array([[0.8, 0.2, 0.0],\n",
        "              [0.1, 0.6, 0.3],\n",
        "              [0.0, 0.1, 0.9]])\n",
        "\n",
        "pi = np.array([.3, .3, .4])\n",
        "\n",
        "animals_hmm = hmm.HiddenMarkovModel(A=A, B=B, pi=pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv3-eiqyklfg",
        "colab_type": "text"
      },
      "source": [
        "May be at this point the code above is a bin unclear, but if we plot what we have declared the things will become a lot clearer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XubiKtN8klfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "outputId": "3faebdac-0095-4012-ccde-4f7a71c6aeb1"
      },
      "source": [
        "animals_hmm.draw(Q_names, V)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f71de4d73c8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Hidden Markov Model Pages: 1 -->\n<svg width=\"418pt\" height=\"392pt\"\n viewBox=\"0.00 0.00 417.90 392.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 388)\">\n<title>Hidden Markov Model</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-388 413.8973,-388 413.8973,4 -4,4\"/>\n<!-- q&#45;0 -->\n<g id=\"node1\" class=\"node\">\n<title>q&#45;0</title>\n<ellipse fill=\"#add8e6\" stroke=\"#add8e6\" cx=\"206.8973\" cy=\"-279\" rx=\"35.9954\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"206.8973\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Sunny</text>\n</g>\n<!-- q&#45;0&#45;&gt;q&#45;0 -->\n<g id=\"edge13\" class=\"edge\">\n<title>q&#45;0&#45;&gt;q&#45;0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M239.1671,-286.863C250.9729,-287.0761 260.6442,-284.4551 260.6442,-279 260.6442,-275.2496 256.073,-272.8388 249.3797,-271.7675\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"249.3638,-268.26 239.1671,-271.137 248.9324,-275.2467 249.3638,-268.26\"/>\n<text text-anchor=\"middle\" x=\"274.1442\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.43</text>\n</g>\n<!-- q&#45;1 -->\n<g id=\"node2\" class=\"node\">\n<title>q&#45;1</title>\n<ellipse fill=\"#add8e6\" stroke=\"#add8e6\" cx=\"92.8973\" cy=\"-192\" rx=\"33.2948\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"92.8973\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Rainy</text>\n</g>\n<!-- q&#45;0&#45;&gt;q&#45;1 -->\n<g id=\"edge14\" class=\"edge\">\n<title>q&#45;0&#45;&gt;q&#45;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M188.0451,-263.5797C175.3978,-253.3336 158.2978,-239.6693 142.8973,-228 136.1836,-222.9128 128.8689,-217.5488 121.9584,-212.5597\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"123.6625,-209.4747 113.4968,-206.4897 119.5822,-215.1626 123.6625,-209.4747\"/>\n<text text-anchor=\"middle\" x=\"173.3973\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.32</text>\n</g>\n<!-- q&#45;2 -->\n<g id=\"node3\" class=\"node\">\n<title>q&#45;2</title>\n<ellipse fill=\"#add8e6\" stroke=\"#add8e6\" cx=\"242.8973\" cy=\"-105\" rx=\"37.8943\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"242.8973\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Snowy</text>\n</g>\n<!-- q&#45;0&#45;&gt;q&#45;2 -->\n<g id=\"edge15\" class=\"edge\">\n<title>q&#45;0&#45;&gt;q&#45;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M216.7869,-261.377C229.1563,-238.1146 249.4907,-195.4797 255.8973,-156 256.9652,-149.4194 257.0467,-147.5668 255.8973,-141 255.4198,-138.2713 254.753,-135.4767 253.9713,-132.71\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"257.2198,-131.3844 250.7696,-122.9794 250.5705,-133.5723 257.2198,-131.3844\"/>\n<text text-anchor=\"middle\" x=\"264.3973\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.26</text>\n</g>\n<!-- o&#45;0 -->\n<g id=\"node4\" class=\"node\">\n<title>o&#45;0</title>\n<ellipse fill=\"#d3f0ce\" stroke=\"#d3f0ce\" cx=\"379.8973\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"379.8973\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Ant</text>\n</g>\n<!-- q&#45;0&#45;&gt;o&#45;0 -->\n<g id=\"edge4\" class=\"edge\">\n<title>q&#45;0&#45;&gt;o&#45;0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M241.4096,-274.024C276.7319,-268.2193 328.3163,-257.5321 341.8973,-243 392.5886,-188.759 389.4273,-93.3575 384.0934,-46.1246\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"387.5422,-45.4962 382.8318,-36.0061 380.596,-46.3623 387.5422,-45.4962\"/>\n<text text-anchor=\"middle\" x=\"396.3973\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.50</text>\n</g>\n<!-- o&#45;1 -->\n<g id=\"node5\" class=\"node\">\n<title>o&#45;1</title>\n<ellipse fill=\"#d3f0ce\" stroke=\"#d3f0ce\" cx=\"29.8973\" cy=\"-18\" rx=\"29.795\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"29.8973\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Snail</text>\n</g>\n<!-- q&#45;0&#45;&gt;o&#45;1 -->\n<g id=\"edge5\" class=\"edge\">\n<title>q&#45;0&#45;&gt;o&#45;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M178.7021,-267.7652C172.5394,-265.4322 166.0265,-263.0594 159.8973,-261 109.1978,-243.9648 86.1041,-250.2632 50.8973,-210 4.7214,-157.1921 22.3729,-124.003 26.8973,-54 27.0543,-51.5709 27.2327,-49.0508 27.4223,-46.5233\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"30.9311,-46.5516 28.2394,-36.3044 23.9534,-45.9936 30.9311,-46.5516\"/>\n<text text-anchor=\"middle\" x=\"35.3973\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.27</text>\n</g>\n<!-- o&#45;2 -->\n<g id=\"node6\" class=\"node\">\n<title>o&#45;2</title>\n<ellipse fill=\"#d3f0ce\" stroke=\"#d3f0ce\" cx=\"242.8973\" cy=\"-18\" rx=\"50.8918\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"242.8973\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">White Fox</text>\n</g>\n<!-- q&#45;0&#45;&gt;o&#45;2 -->\n<g id=\"edge6\" class=\"edge\">\n<title>q&#45;0&#45;&gt;o&#45;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M226.9324,-264.0572C258.3387,-239.0815 317.3867,-185.4014 334.8973,-123 339.2202,-107.595 342.0528,-101.3108 334.8973,-87 324.0573,-65.3199 302.8075,-48.6845 283.4594,-37.185\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"285.176,-34.1349 274.7478,-32.2632 281.7327,-40.2295 285.176,-34.1349\"/>\n<text text-anchor=\"middle\" x=\"341.3973\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.22</text>\n</g>\n<!-- q&#45;1&#45;&gt;q&#45;0 -->\n<g id=\"edge16\" class=\"edge\">\n<title>q&#45;1&#45;&gt;q&#45;0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M95.7621,-210.0802C98.3262,-220.8732 103.1029,-234.1561 111.8973,-243 125.6437,-256.8236 145.2295,-265.4213 163.0497,-270.7288\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"162.1524,-274.1118 172.7199,-273.3511 163.9846,-267.3558 162.1524,-274.1118\"/>\n<text text-anchor=\"middle\" x=\"125.3973\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.35</text>\n</g>\n<!-- q&#45;1&#45;&gt;q&#45;1 -->\n<g id=\"edge17\" class=\"edge\">\n<title>q&#45;1&#45;&gt;q&#45;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M122.8429,-199.8442C134.421,-200.1929 144.0444,-197.5781 144.0444,-192 144.0444,-188.165 139.4959,-185.7307 132.8907,-184.6971\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"133.0168,-181.1989 122.8429,-184.1558 132.6401,-188.1888 133.0168,-181.1989\"/>\n<text text-anchor=\"middle\" x=\"157.5444\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.35</text>\n</g>\n<!-- q&#45;1&#45;&gt;q&#45;2 -->\n<g id=\"edge18\" class=\"edge\">\n<title>q&#45;1&#45;&gt;q&#45;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M108.7619,-175.6537C120.0211,-164.746 135.9174,-150.6824 151.8973,-141 167.1796,-131.7403 185.264,-124.0128 201.2689,-118.1215\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"202.6698,-121.3382 210.9218,-114.6933 200.3271,-114.7418 202.6698,-121.3382\"/>\n<text text-anchor=\"middle\" x=\"165.3973\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.29</text>\n</g>\n<!-- q&#45;1&#45;&gt;o&#45;0 -->\n<g id=\"edge7\" class=\"edge\">\n<title>q&#45;1&#45;&gt;o&#45;0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M103.4424,-174.856C111.8858,-160.9871 123.9243,-140.8917 133.8973,-123 150.7384,-92.7871 141.59,-73.878 169.8973,-54 194.3054,-36.8601 273.5654,-41.4006 302.8973,-36 316.6404,-33.4696 331.628,-30.1057 344.6978,-26.9712\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"345.8236,-30.2992 354.7079,-24.5268 344.1631,-23.499 345.8236,-30.2992\"/>\n<text text-anchor=\"middle\" x=\"159.3973\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.26</text>\n</g>\n<!-- q&#45;1&#45;&gt;o&#45;1 -->\n<g id=\"edge8\" class=\"edge\">\n<title>q&#45;1&#45;&gt;o&#45;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M77.8834,-175.7852C66.5874,-162.5959 51.7548,-142.9601 43.8973,-123 34.1583,-98.26 30.9543,-67.9754 30.0102,-46.2991\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"33.5031,-46.0084 29.7046,-36.1179 26.5063,-46.2184 33.5031,-46.0084\"/>\n<text text-anchor=\"middle\" x=\"57.3973\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.43</text>\n</g>\n<!-- q&#45;1&#45;&gt;o&#45;2 -->\n<g id=\"edge9\" class=\"edge\">\n<title>q&#45;1&#45;&gt;o&#45;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M91.7473,-173.8318C91.1418,-151.9954 92.636,-114.8216 106.8973,-87 122.6449,-56.2791 157.6318,-38.9526 188.1746,-29.3456\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.2948,-32.6645 197.9048,-26.4905 187.3239,-25.9477 189.2948,-32.6645\"/>\n<text text-anchor=\"middle\" x=\"120.3973\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.32</text>\n</g>\n<!-- q&#45;2&#45;&gt;q&#45;0 -->\n<g id=\"edge19\" class=\"edge\">\n<title>q&#45;2&#45;&gt;q&#45;0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M240.3361,-123.4219C238.3314,-133.5685 234.847,-146.0782 228.8973,-156 222.9152,-165.9761 214.6457,-163.3811 209.8973,-174 199.0216,-198.3217 199.582,-229.0794 202.0677,-251.0064\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"198.6085,-251.5454 203.4009,-260.9943 205.5469,-250.6191 198.6085,-251.5454\"/>\n<text text-anchor=\"middle\" x=\"223.3973\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.26</text>\n</g>\n<!-- q&#45;2&#45;&gt;q&#45;1 -->\n<g id=\"edge20\" class=\"edge\">\n<title>q&#45;2&#45;&gt;q&#45;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M225.3927,-121.1503C213.0474,-131.9705 195.7677,-146.01 178.8973,-156 163.931,-164.8625 146.3758,-172.628 131.0422,-178.6559\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"129.431,-175.5245 121.3363,-182.3602 131.927,-182.0644 129.431,-175.5245\"/>\n<text text-anchor=\"middle\" x=\"212.3973\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.35</text>\n</g>\n<!-- q&#45;2&#45;&gt;q&#45;2 -->\n<g id=\"edge21\" class=\"edge\">\n<title>q&#45;2&#45;&gt;q&#45;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M276.8882,-112.8707C288.871,-112.9966 298.594,-110.373 298.594,-105 298.594,-101.306 293.9984,-98.9116 287.2322,-97.8168\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"287.0983,-94.3002 276.8882,-97.1293 286.634,-101.2848 287.0983,-94.3002\"/>\n<text text-anchor=\"middle\" x=\"312.094\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.39</text>\n</g>\n<!-- q&#45;2&#45;&gt;o&#45;0 -->\n<g id=\"edge10\" class=\"edge\">\n<title>q&#45;2&#45;&gt;o&#45;0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M265.8281,-90.4382C289.4042,-75.4665 326.1607,-52.1247 351.5469,-36.0036\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"353.4464,-38.9434 360.0118,-30.628 349.6939,-33.0342 353.4464,-38.9434\"/>\n<text text-anchor=\"middle\" x=\"332.3973\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.22</text>\n</g>\n<!-- q&#45;2&#45;&gt;o&#45;1 -->\n<g id=\"edge11\" class=\"edge\">\n<title>q&#45;2&#45;&gt;o&#45;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M214.1712,-93.2668C175.2744,-77.3794 105.9441,-49.0613 64.3114,-32.0565\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"65.4435,-28.7382 54.8625,-28.197 62.7966,-35.2185 65.4435,-28.7382\"/>\n<text text-anchor=\"middle\" x=\"162.3973\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.24</text>\n</g>\n<!-- q&#45;2&#45;&gt;o&#45;2 -->\n<g id=\"edge12\" class=\"edge\">\n<title>q&#45;2&#45;&gt;o&#45;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M242.8973,-86.9735C242.8973,-75.1918 242.8973,-59.5607 242.8973,-46.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"246.3974,-46.0033 242.8973,-36.0034 239.3974,-46.0034 246.3974,-46.0033\"/>\n<text text-anchor=\"middle\" x=\"256.3973\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.54</text>\n</g>\n<!-- pi -->\n<g id=\"node7\" class=\"node\">\n<title>pi</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"206.8973\" cy=\"-366\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"206.8973\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pi</text>\n</g>\n<!-- pi&#45;&gt;q&#45;0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>pi&#45;&gt;q&#45;0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M206.8973,-347.9735C206.8973,-336.1918 206.8973,-320.5607 206.8973,-307.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"210.3974,-307.0033 206.8973,-297.0034 203.3974,-307.0034 210.3974,-307.0033\"/>\n<text text-anchor=\"middle\" x=\"220.3973\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.30</text>\n</g>\n<!-- pi&#45;&gt;q&#45;1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>pi&#45;&gt;q&#45;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M188.4277,-352.6746C162.2193,-332.4628 115.4704,-291.2585 97.8973,-243 95.3317,-235.9544 93.9135,-228.0202 93.1652,-220.5461\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.6487,-220.1774 92.5038,-210.427 89.6636,-220.634 96.6487,-220.1774\"/>\n<text text-anchor=\"middle\" x=\"142.3973\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.30</text>\n</g>\n<!-- pi&#45;&gt;q&#45;2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>pi&#45;&gt;q&#45;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M229.4935,-356.086C251.287,-345.1408 282.9586,-325.2502 296.8973,-297 328.0317,-233.8988 303.3929,-202.8802 269.8973,-141 267.9449,-137.393 265.6577,-133.7513 263.2552,-130.241\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"265.8847,-127.9061 257.1705,-121.88 260.2248,-132.0251 265.8847,-127.9061\"/>\n<text text-anchor=\"middle\" x=\"324.3973\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.40</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDnJ2junklfw",
        "colab_type": "text"
      },
      "source": [
        "Looking at the plot we can see the probabilities ($\\pi$) of starting at specific hidden state, the transition probabilites and the emission probabilities being at each hidden state.\n",
        "\n",
        "That's all for the Hidden Markov Models introduction. If you want to learn more about them, IMO this [4] notes are a pretty good resource.\n",
        "\n",
        "Now lets move on to our use case of creating positive *soundish* words.\n",
        "\n",
        "## Preprocessing corpus\n",
        "\n",
        "Since our goal is to generate new words, we should work at character level, meaning that characters are going to be the observations and the total number of timesteps, is going to be the word length. For example, a word $W_l$ of length $l$ will be composed of $l$ letters $o_1, o_2, ..., o_l$, in other words, $Wl$ is going to be a sequence of $l$ observations.\n",
        "\n",
        "Now imagine that the generated word is \"hello\". In this case, we have:\n",
        "\n",
        "$W_5 = o_1, o_2, ..., o_5$ where \n",
        "\n",
        "$o_1 = h, o_2 = e, o_3 = l, o_4 = l, o_5 = o$\n",
        "\n",
        "Similar to other Natural Language Processing (NLP) tasks, we cannot work using characters neither words, we have to convert them using a vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r736af42klf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35059486-38e6-4c5f-e6c9-1253127d42df"
      },
      "source": [
        "import string\n",
        "\n",
        "letters = string.ascii_lowercase + '-+'\n",
        "letter2idx = {o: i for i, o in enumerate(letters, start=1)} # Reserve 0 for padding\n",
        "\n",
        "print('hello =', ','.join(str(letter2idx[o]) for o in 'hello'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello = 8,5,12,12,15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4crFTa1_klgA",
        "colab_type": "text"
      },
      "source": [
        "Once we have a way of converting words into numbers, we can load the dataset and convert some random existing words.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRirwUtBlJfs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "21b6e302-3238-4c78-d705-790de0d40842"
      },
      "source": [
        "!wget https://gist.githubusercontent.com/mkulakowski2/4289437/raw/1bb4d7f9ee82150f339f09b5b1a0e6823d633958/positive-words.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-08 10:09:41--  https://gist.githubusercontent.com/mkulakowski2/4289437/raw/1bb4d7f9ee82150f339f09b5b1a0e6823d633958/positive-words.txt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20630 (20K) [text/plain]\n",
            "Saving to: ‘positive-words.txt.1’\n",
            "\n",
            "\rpositive-words.txt.   0%[                    ]       0  --.-KB/s               \rpositive-words.txt. 100%[===================>]  20.15K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2020-03-08 10:09:41 (4.26 MB/s) - ‘positive-words.txt.1’ saved [20630/20630]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx2gUDaQklgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6ee942eb-81a6-4c5c-95a9-d7c6b783e9e0"
      },
      "source": [
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "with open('positive-words.txt') as f:\n",
        "    dataset = [w.strip() for w in f.readlines() \n",
        "               if w.strip() and not w.startswith(';')]\n",
        "\n",
        "print('Number of words:', len(dataset))\n",
        "print(random.sample(dataset, 5))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words: 2006\n",
            "['successfully', 'gallant', 'rosy', 'tops', 'guarantee']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm8-US47klgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2bd0aff1-2d11-434b-df0c-426070720b86"
      },
      "source": [
        "def word2idx(word):\n",
        "    return [letter2idx[o] for o in word]\n",
        "\n",
        "random_words = random.sample(dataset, 5)\n",
        "for w in random_words:\n",
        "    print(f'{w} =', ','.join(map(str, word2idx(w))))    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "altruistic = 1,12,20,18,21,9,19,20,9,3\n",
            "encouragingly = 5,14,3,15,21,18,1,7,9,14,7,12,25\n",
            "won = 23,15,14\n",
            "jubilant = 10,21,2,9,12,1,14,20\n",
            "innocuous = 9,14,14,15,3,21,15,21,19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-fSt_4kklga",
        "colab_type": "text"
      },
      "source": [
        "Now we can easily convert a word to numbers. Pretty interesting, isn't it? But we want to go a bit further. \n",
        "\n",
        "Usually, Machine Learning (ML) models are trained using *batches* of data, and HMMs are not different. So, before moving forward, we need a function that samples $n$ words and packs them into a single tensor. Also, if you are familiar with sequences, you should now that to pack heterogeneous sequences into a single tensor they must have the same size, in other words, they all need to be of size $n$. To achieve that, we usually pad sequences to match the larger sequence inside the batch, which exactly $n$ elements. \n",
        "\n",
        "In addition, to avoid computing probabilities involving padding, we keep track of the length of each word in the batch. This will allow us to stop operating at a determined timestep of the sequences (words) and therfore avoid computations with padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUlYhgodklgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f99b893-7ccf-415d-a655-2b57821417e6"
      },
      "source": [
        "def sampler(batch_size=32, pad_val=-1):\n",
        "    batch = random.sample(dataset, batch_size)\n",
        "    max_len = max(len(o) for o in batch)\n",
        "    padded_batch = []\n",
        "    lengths = []\n",
        "    for b in batch:\n",
        "        offset = max_len - len(b)\n",
        "        lengths.append(len(b))\n",
        "        padded_batch.append(word2idx(b) + [pad_val] * offset)\n",
        "    \n",
        "    return np.array(padded_batch), np.array(lengths).astype('int32')\n",
        "\n",
        "sample_batch = sampler()\n",
        "print('Batch shape [N_SAMPLES, SEQUENCE_LEN]:', sample_batch[0].shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch shape [N_SAMPLES, SEQUENCE_LEN]: (32, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIliOOR9klgn",
        "colab_type": "text"
      },
      "source": [
        "We are done here. Let's move on to the training part.\n",
        "\n",
        "## Training an HMM\n",
        "\n",
        "In this section, we are going to train an HMM from scratch using the package seen above. \n",
        "\n",
        "First of all, we are going to declare an HMM having at least eight possible hidden states and having as many observations as the length of our vocabulary.\n",
        "\n",
        "> Note that the number of hidden states is arbitrary. With a bigger number of hidden states, we will tend to higher variances (probably overfit), and with low values for hidden states will have a higher bias (higher probability of underfitting). Summarizing, the number of hidden states is an hyperparameter, and you have to play with it in order to improve performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3cI0Xzaklgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "key, subkey = jax.random.split(key)\n",
        "\n",
        "words_hmm = hmm.HiddenMarkovModel.random_init(\n",
        "    key, n_hidden_states=16, n_observations=len(letters) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO2nsptlklgy",
        "colab_type": "text"
      },
      "source": [
        "To train our HMM, what we need to do, is to tweak the parameters ($A$, $B$ and $\\pi$) so they maximize the probability of training words to appear.\n",
        "\n",
        "If we now sample a word, we are going to see that it does not make any sense. This is because HMM is randomly intialized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhw3FCQgklg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "832573ad-4458-4983-8185-8c9ee9950ac7"
      },
      "source": [
        "def decode_word(indices):\n",
        "    vocab = list(letters + '-+')\n",
        "    return ''.join(vocab[i] if i >= 0 else '<p>' for i in indices)\n",
        "\n",
        "key, subkey = jax.random.split(key)\n",
        "generated_word = words_hmm.sample(subkey, timesteps=5) # Sample a word with 5 characters\n",
        "print('Generated word:', decode_word(generated_word.reshape(-1)))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated word: t+cuu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6rhfV34klg9",
        "colab_type": "text"
      },
      "source": [
        "In order to create, words with sense, or at least words pretending to have sense, we are going to maximize the probability of training words. To do so, we are going to use Stochastic Gradient Descent (SGD). More precicely, we are going to compute the gradients of the HMM parameters with respect of Negative Log Likelihood (NLL), and substract a small amount of the gradient to our parameters to maximize the training words likelihood.\n",
        "\n",
        "$w_{t+1} = w_t - \\alpha \\frac{\\partial L(w_t)}{\\partial w_t}$\n",
        "\n",
        "where $w$ are the HMM parameters and $L$ is the $NLL$.\n",
        "\n",
        "$NLL = \\frac{\\sum_{n}{-\\log p_i}}{n}$\n",
        "\n",
        "where $p$ is the probability of a given training word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKSycvBjklhA",
        "colab_type": "text"
      },
      "source": [
        "Natively, my `hmm` package does not support *batching* with `likelihood` method. Luckily, JAX allow us to vectorize a function by just decorating it with `jax.vmap`. Also, `hmm` module, does not provide a simple way of computing the gradients of the HMM parameters with respect to an error function, but again, JAX provides the decorator `grad` or `value_and_grad` to automatically compute the derivatives of standard python code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2baHDTOZklhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import partial\n",
        "import hmm.functional as F\n",
        "\n",
        "# To make F.lokelihood to work with batch, we have to take care of all of its \n",
        "# arguments specifying which dimention we want the batch to occur.\n",
        "# For instance, we do not want the hmm to be batched, but words and lengths should\n",
        "# be batched on axis 0 \n",
        "v_likelihood = jax.vmap(F.likelihood, in_axes=(None, 0, 0))\n",
        "\n",
        "# Computes the NLL given the HMM and training words\n",
        "def forward(hmm, words, lengths):\n",
        "    # hmm package works with log probabilities,\n",
        "    # so likelihood method returns the log probability instead of the *standard one*\n",
        "    log_prob = v_likelihood(hmm, words, lengths)\n",
        "    # To compute NLL we just have to neg the probability returned from the \n",
        "    # likelihood method\n",
        "    return -log_prob.mean()\n",
        "\n",
        "# Partial derivative of first arg (HMM params)\n",
        "backward = jax.jit(jax.value_and_grad(forward))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvMjLm8QklhL",
        "colab_type": "text"
      },
      "source": [
        "If we now call `backward`, the function will return us the loss value and the gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9q_CxEUklhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "657e6dea-2f98-4cd7-9335-c22187801331"
      },
      "source": [
        "sample_batch = sampler(batch_size=4)\n",
        "losses, grads = backward(words_hmm, *sample_batch)\n",
        "print('Loss:', losses)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 37.04048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF9357eyklhV",
        "colab_type": "text"
      },
      "source": [
        "If we apply a set of SGD steps with a pretty high learning rate $\\alpha$, we are going to see how the loss decreases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-injYmkNklhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "daeecd52-65eb-40b0-906a-8affb1c70dbb"
      },
      "source": [
        "@jax.jit\n",
        "def train_step(h, words, length):\n",
        "  losses, grads = backward(h, words, length)\n",
        "  h = h - grads * 1e-1\n",
        "  return losses, h\n",
        "\n",
        "for _ in range(200):\n",
        "  losses, words_hmm = train_step(words_hmm, *sample_batch)\n",
        "\n",
        "print('Loss:', losses)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 33.053852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS9XQ9Sjklhg",
        "colab_type": "text"
      },
      "source": [
        "Reapeat SGD for 1000 steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPPvuucBklhj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "outputId": "2c242285-dce4-445b-8f7b-08f84612a40c"
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 16\n",
        "training_steps = len(dataset) // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0\n",
        "  for step in range(training_steps):\n",
        "      loss, words_hmm = train_step(words_hmm, *sampler())\n",
        "      running_loss += loss\n",
        "      \n",
        "      if (step + 1) % 1000 == 0:\n",
        "          mean_loss = running_loss / step\n",
        "          print(f'Step [{epoch}] [{step}/{training_steps}] Loss: {mean_loss:.4f}')\n",
        "          for i in range(3):\n",
        "            length = random.randint(4, 10)\n",
        "            key, subkey = jax.random.split(key)\n",
        "            generated_w = words_hmm.sample(subkey, length).reshape(-1)\n",
        "            print('New word:', decode_word(generated_w))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step [0] [999/5000] Loss: 25.5608\n",
            "New word: zftzvnmnff\n",
            "New word: pofm\n",
            "New word: tiugset\n",
            "Step [0] [1999/5000] Loss: 25.4192\n",
            "New word: uofpmtfut\n",
            "New word: fosfjg\n",
            "New word: etotf\n",
            "Step [0] [2999/5000] Loss: 25.3516\n",
            "New word: djimpbjz\n",
            "New word: jsdlf\n",
            "New word: oufohvumfj\n",
            "Step [0] [3999/5000] Loss: 25.2892\n",
            "New word: ipouhoiffh\n",
            "New word: stqslcrcq\n",
            "New word: ubjsvbfcjo\n",
            "Step [0] [4999/5000] Loss: 25.2462\n",
            "New word: zdbijtf\n",
            "New word: bjof\n",
            "New word: pkn-\n",
            "Step [1] [999/5000] Loss: 25.0463\n",
            "New word: seoee\n",
            "New word: cfnb\n",
            "New word: uzof\n",
            "Step [1] [1999/5000] Loss: 24.9568\n",
            "New word: bfuzg\n",
            "New word: mtjzfejsj\n",
            "New word: bjemsvfdmv\n",
            "Step [1] [2999/5000] Loss: 24.9208\n",
            "New word: cjon\n",
            "New word: bfsfzoi\n",
            "New word: qugudpbfd\n",
            "Step [1] [3999/5000] Loss: 24.9087\n",
            "New word: ejnvb\n",
            "New word: qeffptftnd\n",
            "New word: ojzpot\n",
            "Step [1] [4999/5000] Loss: 24.8793\n",
            "New word: ghjsoo\n",
            "New word: s-ge\n",
            "New word: gwbozdu\n",
            "Step [2] [999/5000] Loss: 24.6993\n",
            "New word: xforfn\n",
            "New word: bfjegbud\n",
            "New word: swtdssqm\n",
            "Step [2] [1999/5000] Loss: 24.6141\n",
            "New word: tbjlsj\n",
            "New word: gpbs\n",
            "New word: ndtedne\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdan2XgRklhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "key, subkey = jax.random.split(key)\n",
        "generated_word = words_hmm.sample(subkey, timesteps=5) # Sample a word with 5 characters\n",
        "print('Generated word:', decode_word(generated_word.reshape(-1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RLxng244EUg",
        "colab_type": "text"
      },
      "source": [
        "We can see how our HMM is creating words that seems that they exists. This is because HMM has *understood* how our language works, in other words, we have created a language model capable of determining the probability of a word existing or not.\n",
        "\n",
        "That's all for today's blog post, I hope you enjoyed it and I am looking forward to see you again here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT4SDXuxklhx",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "[1] Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \n",
        "       Proceedings of the ACM SIGKDD International Conference on Knowledge \n",
        "       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \n",
        "       Washington, USA, \n",
        "\n",
        "[2] Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \n",
        "       and Comparing Opinions on the Web.\" Proceedings of the 14th \n",
        "       International World Wide Web conference (WWW-2005), May 10-14, \n",
        "       2005, Chiba, Japan.\n",
        "\n",
        "[3] Guillem96 - [Implementation of Hidden Markov Models using JAX](https://github.com/Guillem96/jax-hidden-markov-model)\n",
        "\n",
        "[4] Daniel Jurafsky & James H. Martin - [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/A.pdf)"
      ]
    }
  ]
}